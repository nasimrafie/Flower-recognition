{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"LP24ohmjiZci","executionInfo":{"status":"ok","timestamp":1734192109262,"user_tz":480,"elapsed":17290,"user":{"displayName":"Nassim Rafiefard","userId":"15520260782294055271"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import zipfile\n","import shutil\n","\n","# For Data Visualization\n","import cv2\n","import seaborn as sns\n","\n","# For Model Building\n","import tensorflow as tf\n","import keras\n","from tensorflow.keras.models import Sequential, Model # Sequential API for sequential model\n","from tensorflow.keras.layers import Dense, Dropout, Flatten # Importing different layers\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Input, LeakyReLU, Activation\n","from tensorflow.keras import backend\n","from tensorflow.keras.utils import to_categorical # To perform one-hot encoding\n","from tensorflow.keras.optimizers import RMSprop, Adam, SGD # Optimizers for optimizing the model\n","from tensorflow.keras.callbacks import EarlyStopping  # Regularization method to prevent the overfitting\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras import losses, optimizers\n","from tensorflow.keras.preprocessing.image import load_img\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5795,"status":"ok","timestamp":1734192118723,"user":{"displayName":"Nassim Rafiefard","userId":"15520260782294055271"},"user_tz":480},"id":"wQCTgbrdifUf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2afb2806-b63a-43f5-d43e-6d38e82777b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n","\u001b[1m228813984/228813984\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"]}],"source":["flowers_root = tf.keras.utils.get_file(\n","    'flower_photos',\n","    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n","    untar=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1758,"status":"ok","timestamp":1734192121619,"user":{"displayName":"Nassim Rafiefard","userId":"15520260782294055271"},"user_tz":480},"id":"lru-7utFhUQW","outputId":"622872ae-90ac-4685-d4bb-c8173cc8c103"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/flower_photos'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["import shutil\n","\n","# Copy the dataset to /content so it's visible in the Files pane\n","shutil.copytree(flowers_root, '/content/flower_photos')\n","\n","# Now the dataset will appear in the Files section"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":159,"status":"ok","timestamp":1734192126883,"user":{"displayName":"Nassim Rafiefard","userId":"15520260782294055271"},"user_tz":480},"id":"eV6oQy-Skj5k","outputId":"0f4f0f75-4aa5-4444-8f08-9b2652e03d9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["sunflowers Folder has 699 images\n","daisy Folder has 633 images\n","dandelion Folder has 898 images\n","tulips Folder has 799 images\n","roses Folder has 641 images\n","Images Folder has 3670 images in total.\n"]}],"source":["\n","\n","# Now the dataset will appear in the Files section\n","count = 0\n","dirs = os.listdir('/content/flower_photos')\n","\n","for dir in dirs:\n","    # Correctly join the paths\n","    folder_path = os.path.join('/content/flower_photos', dir)\n","    if os.path.isdir(folder_path):  # Ensure it is a directory\n","        files = os.listdir(folder_path)\n","        print(dir + ' Folder has ' + str(len(files)) + ' images')\n","        count += len(files)\n","\n","print('Images Folder has ' + str(count) + ' images in total.')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1971,"status":"ok","timestamp":1734192134890,"user":{"displayName":"Nassim Rafiefard","userId":"15520260782294055271"},"user_tz":480},"id":"kqGdM5zXY5Tp","outputId":"fee92b7b-2886-4fe9-d1c4-81615061951d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2934 files belonging to 5 classes.\n","Found 736 files belonging to 5 classes.\n","Class names: ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n","\n","Training Data Structure:\n","sunflowers: 559 images\n","daisy: 506 images\n","dandelion: 718 images\n","tulips: 639 images\n","roses: 512 images\n","\n","Testing Data Structure:\n","sunflowers: 140 images\n","daisy: 127 images\n","dandelion: 180 images\n","tulips: 160 images\n","roses: 129 images\n"]}],"source":["import os\n","import shutil\n","import random\n","import tensorflow as tf\n","\n","# Define parameters\n","base_dir = '/content/flower_photos'  # Original directory containing subfolders\n","img_size = 180  # Image size\n","batch = 32  # Batch size for loading data\n","train_dir = '/content/flower_photos_train'  # Directory to store training data\n","test_dir = '/content/flower_photos_test'  # Directory to store testing data\n","split_ratio = 0.8  # 80% for training, 20% for testing\n","\n","# Function to split and move the data into train and test directories\n","def move_data(base_dir, train_dir, test_dir, split_ratio=0.8):\n","    \"\"\"\n","    Move the images from the source folder to train and test folders.\n","\n","    Args:\n","        base_dir (str): The directory containing category subfolders (e.g., 'daisy', 'dandelion').\n","        train_dir (str): The directory to store training images.\n","        test_dir (str): The directory to store testing images.\n","        split_ratio (float): Ratio of data to use for training (default: 0.8 for training, 0.2 for testing).\n","    \"\"\"\n","    # Loop through each class folder (e.g., 'daisy', 'dandelion')\n","    for class_name in os.listdir(base_dir):\n","        class_path = os.path.join(base_dir, class_name)\n","\n","        # Skip if it's not a directory\n","        if not os.path.isdir(class_path):\n","            continue\n","\n","        # Create subdirectories for each class in train and test directories\n","        train_class_dir = os.path.join(train_dir, class_name)\n","        test_class_dir = os.path.join(test_dir, class_name)\n","\n","        os.makedirs(train_class_dir, exist_ok=True)\n","        os.makedirs(test_class_dir, exist_ok=True)\n","\n","        # List all files in the class folder\n","        files = os.listdir(class_path)\n","        random.shuffle(files)  # Shuffle the files to ensure random splitting\n","\n","        # Split files into training and testing sets\n","        split_index = int(len(files) * split_ratio)\n","        train_files = files[:split_index]\n","        test_files = files[split_index:]\n","\n","        # Move files to the respective train and test subdirectories\n","        for file_name in train_files:\n","            shutil.copy(os.path.join(class_path, file_name), train_class_dir)\n","        for file_name in test_files:\n","            shutil.copy(os.path.join(class_path, file_name), test_class_dir)\n","\n","# Move the data into train/test directories\n","move_data(base_dir, train_dir, test_dir, split_ratio)\n","\n","# Load the data using image_dataset_from_directory\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    train_dir,\n","    seed=123,\n","    batch_size=batch,\n","    image_size=(img_size, img_size)\n",")\n","\n","val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    test_dir,\n","    seed=123,\n","    batch_size=batch,\n","    image_size=(img_size, img_size)\n",")\n","\n","# Get class names from the training dataset\n","flower_names = train_ds.class_names\n","print(\"Class names:\", flower_names)\n","\n","# Check the structure of the datasets\n","print(\"\\nTraining Data Structure:\")\n","for class_name in os.listdir(train_dir):\n","    print(f\"{class_name}: {len(os.listdir(os.path.join(train_dir, class_name)))} images\")\n","\n","print(\"\\nTesting Data Structure:\")\n","for class_name in os.listdir(test_dir):\n","    print(f\"{class_name}: {len(os.listdir(os.path.join(test_dir, class_name)))} images\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":329,"status":"ok","timestamp":1734192144099,"user":{"displayName":"Nassim Rafiefard","userId":"15520260782294055271"},"user_tz":480},"id":"X_zxb14snsI8","outputId":"05086994-ba98-4321-9f6c-c7e5d883f170"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}],"source":["from keras import layers\n","from keras import models\n","\n","img_size = 180  # Ensure this matches the dataset\n","model = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dropout(0.5),  # Dropout layer added here\n","    layers.Dense(512, activation='relu'),\n","    layers.Dense(5, activation='softmax')  # Use 5 because there are 5 flower classes\n","])\n","\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"yeHHzKanqVsV","executionInfo":{"status":"ok","timestamp":1734192149457,"user_tz":480,"elapsed":216,"user":{"displayName":"Nassim Rafiefard","userId":"15520260782294055271"}}},"outputs":[],"source":["model.compile(\n","    loss='sparse_categorical_crossentropy',  # Use this for integer labels\n","    optimizer='adam',  # Adam optimizer as an alternative to RMSprop\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kWMYklWQq0HF","outputId":"f4fa2a6e-a717-4ddc-f829-6f21147cf8ac","executionInfo":{"status":"ok","timestamp":1734199933204,"user_tz":480,"elapsed":7779423,"user":{"displayName":"Nassim Rafiefard","userId":"15520260782294055271"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 3s/step - accuracy: 0.2339 - loss: 20.1180 - val_accuracy: 0.2473 - val_loss: 1.5999\n","Epoch 2/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 3s/step - accuracy: 0.2671 - loss: 1.5919 - val_accuracy: 0.2446 - val_loss: 1.5987\n","Epoch 3/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 3s/step - accuracy: 0.2565 - loss: 1.5878 - val_accuracy: 0.2486 - val_loss: 1.5979\n","Epoch 4/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 3s/step - accuracy: 0.2670 - loss: 1.5814 - val_accuracy: 0.2473 - val_loss: 1.6056\n","Epoch 5/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 3s/step - accuracy: 0.2636 - loss: 1.5829 - val_accuracy: 0.2473 - val_loss: 1.6176\n","Epoch 6/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 3s/step - accuracy: 0.2761 - loss: 1.5676 - val_accuracy: 0.2391 - val_loss: 1.6221\n","Epoch 7/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 3s/step - accuracy: 0.2974 - loss: 1.5532 - val_accuracy: 0.2351 - val_loss: 1.6077\n","Epoch 8/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 3s/step - accuracy: 0.2772 - loss: 1.5669 - val_accuracy: 0.2527 - val_loss: 1.6001\n","Epoch 9/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 3s/step - accuracy: 0.2894 - loss: 1.5661 - val_accuracy: 0.2473 - val_loss: 1.6447\n","Epoch 10/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 3s/step - accuracy: 0.2738 - loss: 1.5537 - val_accuracy: 0.2418 - val_loss: 1.6108\n","Epoch 11/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 3s/step - accuracy: 0.3025 - loss: 1.5339 - val_accuracy: 0.2690 - val_loss: 1.5872\n","Epoch 12/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 3s/step - accuracy: 0.3063 - loss: 1.4921 - val_accuracy: 0.3179 - val_loss: 1.5419\n","Epoch 13/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - accuracy: 0.3582 - loss: 1.4458 - val_accuracy: 0.2799 - val_loss: 1.5709\n","Epoch 14/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 3s/step - accuracy: 0.3399 - loss: 1.4570 - val_accuracy: 0.2568 - val_loss: 1.5795\n","Epoch 15/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 3s/step - accuracy: 0.3493 - loss: 1.4215 - val_accuracy: 0.3777 - val_loss: 1.4976\n","Epoch 16/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 3s/step - accuracy: 0.4380 - loss: 1.3489 - val_accuracy: 0.4946 - val_loss: 1.2386\n","Epoch 17/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 3s/step - accuracy: 0.5227 - loss: 1.1984 - val_accuracy: 0.5598 - val_loss: 1.1743\n","Epoch 18/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 3s/step - accuracy: 0.5959 - loss: 1.0247 - val_accuracy: 0.5938 - val_loss: 1.1134\n","Epoch 19/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 3s/step - accuracy: 0.6816 - loss: 0.8447 - val_accuracy: 0.5938 - val_loss: 1.0755\n","Epoch 20/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 3s/step - accuracy: 0.7157 - loss: 0.7762 - val_accuracy: 0.5951 - val_loss: 1.1244\n","Epoch 21/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 3s/step - accuracy: 0.7512 - loss: 0.6786 - val_accuracy: 0.6060 - val_loss: 1.1639\n","Epoch 22/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 3s/step - accuracy: 0.7544 - loss: 0.6511 - val_accuracy: 0.6060 - val_loss: 1.1520\n","Epoch 23/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 3s/step - accuracy: 0.8014 - loss: 0.5287 - val_accuracy: 0.6264 - val_loss: 1.1851\n","Epoch 24/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 3s/step - accuracy: 0.8282 - loss: 0.4795 - val_accuracy: 0.6209 - val_loss: 1.2080\n","Epoch 25/25\n","\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 3s/step - accuracy: 0.8218 - loss: 0.5010 - val_accuracy: 0.6427 - val_loss: 1.2298\n"]}],"source":["history = model.fit(\n","    train_ds,  # Training dataset\n","    validation_data=val_ds,  # Validation dataset\n","    epochs=25,  # Number of epochs\n","    verbose=1\n",")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"59UgpsHpq166","executionInfo":{"status":"ok","timestamp":1734200279662,"user_tz":480,"elapsed":159,"user":{"displayName":"Nassim Rafiefard","userId":"15520260782294055271"}}},"outputs":[],"source":["def classify_images(image_path):\n","    input_image = tf.keras.utils.load_img(image_path, target_size=(180,180))\n","    input_image_array = tf.keras.utils.img_to_array(input_image)\n","    input_image_exp_dim = tf.expand_dims(input_image_array,0)\n","\n","    predictions = model.predict(input_image_exp_dim)\n","    result = tf.nn.softmax(predictions[0])\n","    outcome = 'The Image belongs to ' + flower_names[np.argmax(result)] + ' with a score of '+ str(np.max(result)*100)\n","    return outcome"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"zpS9t6DjsrMh","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1734200312727,"user_tz":480,"elapsed":714,"user":{"displayName":"Nassim Rafiefard","userId":"15520260782294055271"}},"outputId":"92969b20-3d2d-42bb-8c56-1c896d7728d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["'The Image belongs to sunflowers with a score of 40.454769134521484'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}],"source":["classify_images('/content/sunflower.jpeg')"]},{"cell_type":"code","source":["classify_images('/content/Rose.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"_ShLvE6aZP3l","executionInfo":{"status":"ok","timestamp":1734200348201,"user_tz":480,"elapsed":491,"user":{"displayName":"Nassim Rafiefard","userId":"15520260782294055271"}},"outputId":"d221443c-4de7-4bfc-b660-fb53d9850bd3"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["'The Image belongs to roses with a score of 30.46633005142212'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["classify_images('/content/tulip.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"wJtk8iuqZUuF","executionInfo":{"status":"ok","timestamp":1734200367393,"user_tz":480,"elapsed":339,"user":{"displayName":"Nassim Rafiefard","userId":"15520260782294055271"}},"outputId":"92d83a5a-7e4b-441b-9e70-25d918a2f91e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["'The Image belongs to tulips with a score of 25.87929666042328'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[],"metadata":{"id":"h3vZnFIvZZcd"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyPLTVUZBaqwaDQ+ibDvzhts"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}